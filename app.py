# app.py
# ì‹¤í–‰ë°©ë²•: streamlit run app.py

import streamlit as st
import pandas as pd
import numpy as np
import os
import re
import json

# --- í™˜ê²½ ì„¤ì • ---
DATA_DIR = "dataSet"
PERSONA_AXES = ['narrative', 'freedom', 'stability', 'challenge']
PERSONA_LABELS_KO = {
    'narrative': 'ìŠ¤í† ë¦¬/ì„œì‚¬ ì„ í˜¸',
    'freedom': 'ììœ ë„/íƒí—˜ ì„ í˜¸',
    'stability': 'ìµœì í™”/ì•ˆì •ì„± ì„ í˜¸',
    'challenge': 'ë„ì „/ë‚œì´ë„ ì„ í˜¸'
}

# ë°ì´í„° ë¡œë“œ ë° ìºì‹±
@st.cache_data
def load_data(filename):
    """ë¶„ì„ëœ CSV íŒŒì¼ê³¼ BERT ë¶„ì„ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    
    # 1-1. ë¶„ì„ëœ ë¦¬ë·° ë°ì´í„° (CSV) ë¡œë“œ
    csv_path = os.path.join(DATA_DIR, f"analyzed_{filename}_reviews.csv")
    try:
        df = pd.read_csv(csv_path)
    except FileNotFoundError:
        return None, None, f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}"

    # 1-2. BERT ë¶„ì„ ê²°ê³¼ (TXT) ë¡œë“œ
    txt_path = os.path.join(DATA_DIR, f"BERT_Analysis_{filename}.txt")
    bert_summary = {}
    try:
        with open(txt_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # í…ìŠ¤íŠ¸ íŒŒì¼ ë‚´ìš© íŒŒì‹± (ê°„ë‹¨í•˜ê²Œ ìš”ì•½ê³¼ íƒœê·¸ë§Œ ì¶”ì¶œ)
        summary_match = re.search(r"ìš”ì•½:\n(.*?)\n\n", content, re.DOTALL)
        tag_match = re.search(r"ì¶”ì²œ íƒœê·¸:\n(.*?)\n\n", content, re.DOTALL)
        
        bert_summary['summary'] = summary_match.group(1).strip() if summary_match else "BERT ìš”ì•½ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        bert_summary['tags'] = [t.strip() for t in tag_match.group(1).split(',') if tag_match] if tag_match else []

    except FileNotFoundError:
        return df, None, f"âš ï¸ BERT ë¶„ì„ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {txt_path}"
    
    return df, bert_summary, None

# ê°œì¸í™” ë¡œì§: ì‚¬ìš©ì ì„ í˜¸ë„ ê¸°ë°˜ ë¦¬ë·° ì ìˆ˜ ê³„ì‚°
def get_personalized_recommendation(df, user_persona_vector):
    """
    ì‚¬ìš©ì ì„±í–¥ ë²¡í„°ì™€ ê° ë¦¬ë·°ì˜ ì„±í–¥ ë²¡í„°ë¥¼ ë¹„êµí•˜ì—¬ ì ìˆ˜í™”í•˜ê³  ê°œì¸í™”ëœ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    # 1. ì‚¬ìš©ì ë²¡í„° ì •ê·œí™” (ì´í•© 1)
    user_vector = np.array(list(user_persona_vector.values()))
    if np.sum(user_vector) > 0:
        user_vector = user_vector / np.sum(user_vector)
    
    # 2. ë¦¬ë·°ë³„ ì„±í–¥ ë²¡í„° ì¶”ì¶œ
    review_vectors = df[[f'S_{axis}' for axis in PERSONA_AXES]].values
    
    # 3. ê°œì¸í™” ì ìˆ˜ ê³„ì‚° (Dot Product)
    # ì‚¬ìš©ì ì„ í˜¸ë„ì™€ ë¦¬ë·°ì˜ ì„±í–¥ ì¼ì¹˜ ì •ë„ë¥¼ ì ìˆ˜í™”
    df['personalized_score'] = np.dot(review_vectors, user_vector)
    
    # 4. ê°€ì¥ ì„ í˜¸ë„ê°€ ë†’ì€ ìƒìœ„ 10ê°œ ë¦¬ë·° ì¶”ì¶œ
    top_n = 10
    personalized_df = df.sort_values(by='personalized_score', ascending=False).head(top_n)
    
    # 5. ê°œì¸í™”ëœ ìš”ì•½ ìƒì„± (ì„ í˜¸ë„ ë†’ì€ ë¦¬ë·°ì˜ í‚¤ì›Œë“œ ê¸°ë°˜)
    top_reviews_text = " ".join(personalized_df['review_text'].tolist())
    
    # 6. ê°œì¸í™” íƒœê·¸ ì¶”ì¶œ (ì„ í˜¸ë„ê°€ ë†’ì€ ë¦¬ë·°ì—ì„œ ìì£¼ ì–¸ê¸‰ëœ í‚¤ì›Œë“œ ê¸°ë°˜)
    # ì´ ë¶€ë¶„ì€ BERTì˜ í‚¤ì›Œë“œ ì¶”ì¶œ ê¸°ëŠ¥ì„ ëŒ€ì²´í•˜ëŠ” ë‹¨ìˆœ í‚¤ì›Œë“œ ì¹´ìš´íŒ…ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.
    
    all_keywords = []
    # ì˜ˆì‹œë¡œ ì„ í˜¸ ì„±í–¥ê³¼ ê´€ë ¨ëœ íƒœê·¸ë§Œ ì¶”ì¶œ
    for axis in PERSONA_AXES:
        if user_persona_vector[axis] > 0.3: # ì‚¬ìš©ìê°€ ê°•í•˜ê²Œ ì„ í˜¸í•˜ëŠ” ì„±í–¥
            # generator_bert.pyì— ì •ì˜ëœ íƒœê·¸ í›„ë³´ë¥¼ ì„ì‹œë¡œ ì‚¬ìš©
            TAG_CANDIDATES = {
                'narrative': ["#ê°“ì„œì‚¬", "#ìŠ¤í† ë¦¬_ëª°ì…", "#ê°ë™ì "],
                'freedom': ["#ë†’ì€_ììœ ë„", "#íƒí—˜", "#ë‚˜ë§Œì˜_ì„ íƒ"],
                'stability': ["#ê°“ì í™”", "#ë²„ê·¸ì—†ìŒ", "#ì¾Œì í•¨"],
                'challenge': ["#í•µì‹¬_ë‚œì´ë„", "#ë„ì „ì˜ì‹", "#í”¼ì§€ì»¬_ê²Œì„"]
            }
            all_keywords.extend(TAG_CANDIDATES.get(axis, []))

    return top_reviews_text, list(set(all_keywords)) # ì¤‘ë³µ ì œê±°

# Streamlit ì•± ë ˆì´ì•„ì›ƒ
def app():
    st.set_page_config(page_title="ê²Œì„ ë¦¬ë·° ì„±í–¥ ë¶„ì„ê¸°", layout="wide")
    st.title("ğŸ® ê²Œì„ ë¦¬ë·° ì„±í–¥ ê¸°ë°˜ ë¶„ì„ ë° ì¶”ì²œê¸°")
    st.markdown("---")

    # 1. ê²Œì„ íŒŒì¼ ì„ íƒ
    try:
        # dataSet ë””ë ‰í† ë¦¬ì—ì„œ 'analyzed_'ë¡œ ì‹œì‘í•˜ëŠ” CSV íŒŒì¼ ëª©ë¡ ë¡œë“œ
        available_files = [f.replace('analyzed_', '').replace('_reviews.csv', '') 
                           for f in os.listdir(DATA_DIR) if f.startswith('analyzed_') and f.endswith('.csv')]
    except FileNotFoundError:
        available_files = []
        st.error(f"âŒ '{DATA_DIR}' ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í¬ë¡¤ë§ ë° ë¶„ì„ì„ ë¨¼ì € ì§„í–‰í•´ì£¼ì„¸ìš”.")
        return

    if not available_files:
        st.warning("ë¶„ì„ëœ ê²Œì„ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. `crawler.py`ì™€ Jupyter Notebook ë¶„ì„ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    game_name_select = st.selectbox("ë¶„ì„í•  ê²Œì„ì„ ì„ íƒí•˜ì„¸ìš”:", available_files)
    
    # ë°ì´í„° ë¡œë“œ
    df, bert_summary, error_message = load_data(game_name_select)

    if error_message:
        st.error(error_message)
        return
    
    # --- 2. ì‚¬ìš©ì ì„±í–¥ ì…ë ¥ ---
    st.header("ğŸ‘¤ ì‚¬ìš©ì ì„ í˜¸ ì„±í–¥ ì…ë ¥")
    st.markdown("ê° ì¶•ì„ ì¡°ì ˆí•˜ì—¬ **'ì‚¬ìš©ìë‹˜'ì´ ê²Œì„ì„ ì„ íƒí•  ë•Œ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ìš”ì†Œ**ì˜ ë¹„ì¤‘ì„ ì„¤ì •í•´ì£¼ì„¸ìš”. (ì´í•©ì€ ë¬´ì‹œë¨)")

    user_persona_input = {}
    cols = st.columns(4)
    
    # ìŠ¬ë¼ì´ë”ë¥¼ í†µí•´ 4ê°€ì§€ ì„±í–¥ ì…ë ¥
    for i, axis in enumerate(PERSONA_AXES):
        with cols[i]:
            user_persona_input[axis] = st.slider(
                label=PERSONA_LABELS_KO[axis],
                min_value=0,
                max_value=10,
                value=5,
                key=axis
            )
            
    # ë²„íŠ¼ í´ë¦­ ì‹œ ë¶„ì„ ì‹œì‘
    if st.button("âœ¨ ê°œì¸í™” ë¶„ì„ ì‹œì‘"):
        
        st.markdown("---")
        st.header(f"ê²°ê³¼: '{game_name_select}' ë§ì¶¤í˜• ë¶„ì„")
        
        # --- 3. ì „ì²´ ìš”ì•½ (BERT ê²°ê³¼) ---
        st.subheader("ğŸ“ ì „ì²´ ë¦¬ë·° ê¸°ë°˜ ê²Œì„ ìš”ì•½ (BERT)")
        if bert_summary and bert_summary.get('summary'):
            st.info(bert_summary['summary'])
        else:
            st.warning("BERT ìš”ì•½ ë¶„ì„ ê²°ê³¼ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        # --- 4. ê°œì¸í™”ëœ ì¶”ì²œ íƒœê·¸ ë° ìš”ì•½ ---
        user_vector_dict = {axis: user_persona_input[axis] for axis in PERSONA_AXES}
        top_reviews_text, personalized_tags = get_personalized_recommendation(df, user_vector_dict)
        
        st.subheader("ğŸ’¡ ì‚¬ìš©ì ë§ì¶¤í˜• ì¶”ì²œ íƒœê·¸")
        
        # ì„ í˜¸ íƒœê·¸ ì¶œë ¥
        tag_display = " ".join([f'<span style="background-color:#007BFF; color:white; padding:5px 10px; border-radius:15px; margin-right:5px; font-weight:bold;">{tag}</span>' for tag in personalized_tags])
        st.markdown(tag_display, unsafe_allow_html=True)
        
        st.markdown("---")
        
        st.subheader("ğŸ“– ê°œì¸í™” ìš”ì•½ ë° ì¶”ì²œ ë¦¬ë·° (ìƒìœ„ 10ê°œ ë¦¬ë·° ê¸°ë°˜)")
        st.write(f"**{game_name_select}** ê²Œì„ì€ ì‚¬ìš©ìë‹˜ì´ ì„ í˜¸í•˜ì‹œëŠ” **{', '.join([PERSONA_LABELS_KO[k] for k, v in user_vector_dict.items() if v >= 7])}** ì„±í–¥ì˜ ë¦¬ë·°ì–´ë“¤ë¡œë¶€í„° ë†’ì€ í‰ê°€ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤. ì‚¬ìš©ìë‹˜ê³¼ ì·¨í–¥ì´ ë¹„ìŠ·í•œ ìƒìœ„ 10ê°œ ë¦¬ë·°ì˜ í•µì‹¬ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:")
        
        # ë‹¨ìˆœ ìš”ì•½ ëŒ€ì‹ , BERTê°€ ì—†ìœ¼ë¯€ë¡œ ìƒìœ„ ë¦¬ë·° í…ìŠ¤íŠ¸ë¥¼ ë³´ì—¬ì¤Œ
        st.code(top_reviews_text[:1000] + "...", language='text')

if __name__ == "__main__":
    app()